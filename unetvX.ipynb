{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>CNN Homework</ins>\n",
    "### David Fan 范庭維 312831023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's begin with creating the U-Net architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution Block \n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Up Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "        \n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(in_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "       # self.active = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "        #d1 = self.active(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to import the underwater images for our model!\n",
    "### I decided to merge the underwater_imagenet and underwater_scenes image datasets into one and use a 80-20 train-test split on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image  # Make sure to import Image from the PIL library\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_size=(256, 256), file_list=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size  # Set the target size for resizing\n",
    "\n",
    "        # Use the provided file list or list all the image files in the folder\n",
    "        self.file_list = file_list if file_list is not None else sorted(os.listdir(root_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.file_list[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_filename)\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Resize the image to the target size\n",
    "        img = img.resize(self.target_size, Image.BICUBIC)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path_A = r'./underwater/trainA'\n",
    "dataset_path_B = r'./underwater/trainB'\n",
    "\n",
    "# Define data transformations (including resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to the target size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# List all the image files in the folder\n",
    "all_image_files = sorted(os.listdir(dataset_path_A))\n",
    "\n",
    "# Split the dataset into training and test sets (80-20%)\n",
    "train_files_A, test_files_A = train_test_split(all_image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create custom datasets for training and test\n",
    "trainA_dataset = CustomDataset(dataset_path_A, transform=transform, file_list=train_files_A)\n",
    "testA_dataset = CustomDataset(dataset_path_A, transform=transform, file_list=test_files_A)\n",
    "\n",
    "trainB_dataset = CustomDataset(dataset_path_B, transform=transform, file_list=train_files_A)\n",
    "testB_dataset = CustomDataset(dataset_path_B, transform=transform, file_list=test_files_A)\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "trainA_loader = DataLoader(trainA_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testA_loader = DataLoader(testA_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "trainB_loader = DataLoader(trainB_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testB_loader = DataLoader(testB_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore this code below, it is just to check my dataset ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def show_image(dataset, index):\n",
    "#     img = dataset[index]\n",
    "#     img_np = img.permute(1, 2, 0).numpy()  # Convert tensor to NumPy array\n",
    "#     plt.imshow(img_np)\n",
    "#     plt.title(f'Dataset: {dataset.root_dir}, Image {index}')\n",
    "#     plt.show()\n",
    "\n",
    "# # Show an image from trainA_dataset\n",
    "# show_image(trainA_dataset, 2)\n",
    "\n",
    "# # Show an image from trainB_dataset\n",
    "# show_image(trainB_dataset, 2)\n",
    "\n",
    "# # Show an image from valA_dataset\n",
    "# show_image(valA_dataset, 2)\n",
    "\n",
    "# # Show an image from valB_dataset\n",
    "# show_image(valB_dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some required and helpful functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples=1\n",
    "\n",
    "def plot_images(input_images, output_images, target_images, epoch):\n",
    "    input_grid = make_grid(input_images.cpu(), nrow=num_samples, normalize=True)\n",
    "    output_grid = make_grid(output_images.cpu(), nrow=num_samples, normalize=True)\n",
    "    target_grid = make_grid(target_images.cpu(), nrow=num_samples, normalize=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(input_grid.permute(1, 2, 0).numpy())\n",
    "    plt.title(f'Epoch {epoch + 1} - Input Images')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(output_grid.permute(1, 2, 0).numpy())\n",
    "    plt.title(f'Epoch {epoch + 1} - Output Images')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(target_grid.permute(1, 2, 0).numpy())\n",
    "    plt.title(f'Epoch {epoch + 1} - Target Images')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def PSNR(img,target): # tensor / tensor\n",
    "    mse = torch.mean((img - target) ** 2)\n",
    "    return 10 * torch.log10(1 / mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our U-Net model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the learning rate scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "epochs = 50\n",
    "\n",
    "# Initialize model, loss function, optimizer, and learning rate scheduler\n",
    "model = U_Net(in_ch=3, out_ch=3).cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)  # Adjust parameters as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and saving our U-Net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/148 [01:26<?, ?it/s, Loss=0.567, PSNR=2.46, SSIM=0.0132]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# Lists to store training losses for plotting\n",
    "train_losses = []\n",
    "print_interval=10\n",
    "num_samples=1\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(zip(trainA_loader, trainB_loader), total=len(trainA_loader)) as t:\n",
    "        for batch_A, batch_B in t:\n",
    "            input_images = batch_A.cuda()\n",
    "            target_images = batch_B.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_images)\n",
    "            loss = criterion(outputs, target_images)\n",
    "            # Compute PSNR and SSIM\n",
    "            psnrV = PSNR(outputs, target_images)\n",
    "            ssimV = ssim(outputs, target_images, data_range=1.0, size_average=True)\n",
    "\n",
    "            # Add PSNR and SSIM to the progress bar\n",
    "            t.set_postfix({'Loss': loss.item(), 'PSNR': psnrV.item(), 'SSIM': ssimV.item()})\n",
    "\n",
    "            # Backpropagation and optimization steps\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Print input and output images after each epoch\n",
    "        if (epoch % print_interval == 0):\n",
    "            with torch.no_grad():\n",
    "                # Take a few samples from the batch\n",
    "                sample_indices = np.random.choice(len(input_images), size=num_samples, replace=False)\n",
    "                sample_input_images = input_images[sample_indices]\n",
    "                sample_target_images = target_images[sample_indices]\n",
    "                sample_output_images = outputs[sample_indices]\n",
    "\n",
    "                # Display the images\n",
    "                plot_images(sample_input_images, sample_output_images, sample_target_images, epoch)\n",
    "\n",
    "    scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {loss} , PSNR: {psnrV}, SSIM: {ssimV}')\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "# Print final PSNR and SSIM values\n",
    "print(f'Final PSNR: {psnrV.item()}')\n",
    "print(f'Final SSIM: {ssimV.item()}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), './trained_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the downward training loss curve, it seems like our model has been able to learn something. Let's use the test dataset from earlier to verify this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = U_Net(in_ch=3, out_ch=3).cuda()\n",
    "model.load_state_dict(torch.load(\"./trained_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Lists to store test PSNR scores\n",
    "img_psnr = []\n",
    "out_psnr = []\n",
    "\n",
    "# Testing loop\n",
    "with torch.no_grad():\n",
    "    for idx, (testA_batch, testB_batch) in tqdm(enumerate(zip(testA_loader, testB_loader)), total=len(testA_loader), desc='Testing Progress'):\n",
    "        input_images = testA_batch.cuda()\n",
    "        target_images = testB_batch.cuda()\n",
    "\n",
    "        # Apply the model to input images\n",
    "        outputs = model(input_images)\n",
    "\n",
    "        # Compute PSNR scores\n",
    "        psnr_input = PSNR(input_images, target_images)\n",
    "        psnr_output = PSNR(outputs, target_images)\n",
    "\n",
    "        # Append PSNR scores to the lists\n",
    "        img_psnr.append(psnr_input.item())\n",
    "        out_psnr.append(psnr_output.item())\n",
    "\n",
    "        # Display images (you can modify this part as needed)\n",
    "        with torch.no_grad():\n",
    "            # Take a few samples from the batch\n",
    "            sample_indices = np.random.choice(len(input_images), size=num_samples, replace=False)\n",
    "            sample_input_images = input_images[sample_indices]\n",
    "            sample_target_images = target_images[sample_indices]\n",
    "            sample_output_images = outputs[sample_indices]\n",
    "\n",
    "            # Display the images\n",
    "            plot_images(sample_input_images, sample_output_images, sample_target_images, epoch)\n",
    "\n",
    "# Compute and print the average PSNR for input and output\n",
    "avg_psnr_input = np.mean(img_psnr)\n",
    "avg_psnr_output = np.mean(out_psnr)\n",
    "print(f'Average PSNR for Input Images: {avg_psnr_input}')\n",
    "print(f'Average PSNR for Output Images: {avg_psnr_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! Let's check it's performance on the underwater_dark dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dark dataset\n",
    "dark_dataset_path_A = r'./underwater_dark/trainA'\n",
    "dark_dataset_path_B = r'./underwater_dark/trainB'\n",
    "\n",
    "# Create custom datasets for dark dataset\n",
    "dark_dataset_A = CustomDataset(dark_dataset_path_A, transform=transform)\n",
    "dark_dataset_B = CustomDataset(dark_dataset_path_B, transform=transform)\n",
    "\n",
    "# Create data loaders for dark dataset\n",
    "dark_loader_A = DataLoader(dark_dataset_A, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dark_loader_B = DataLoader(dark_dataset_B, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = U_Net(in_ch=3, out_ch=3).cuda()\n",
    "model.load_state_dict(torch.load(\"./trained_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Lists to store validation PSNR scores\n",
    "dark_img_psnr = []\n",
    "dark_out_psnr = []\n",
    "\n",
    "# Testing loop on the dark dataset\n",
    "with torch.no_grad():\n",
    "    for idx, (darkA_batch, darkB_batch) in tqdm(enumerate(zip(dark_loader_A, dark_loader_B)), total=len(dark_loader_A), desc='Testing on Dark Dataset'):\n",
    "        dark_input_images = darkA_batch.cuda()\n",
    "        dark_target_images = darkB_batch.cuda()\n",
    "\n",
    "        # Apply the model to input images\n",
    "        dark_outputs = model(dark_input_images)\n",
    "\n",
    "        # Compute PSNR scores\n",
    "        dark_psnr_input = PSNR(dark_input_images, dark_target_images)\n",
    "        dark_psnr_output = PSNR(dark_outputs, dark_target_images)\n",
    "\n",
    "        # Append PSNR scores to the lists\n",
    "        dark_img_psnr.append(dark_psnr_input.item())\n",
    "        dark_out_psnr.append(dark_psnr_output.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Take a few samples from the batch\n",
    "            sample_indices = np.random.choice(len(dark_input_images), size=num_samples, replace=False)\n",
    "            sample_dark_input_images = dark_input_images[sample_indices]\n",
    "            sample_dark_target_images = dark_target_images[sample_indices]\n",
    "            sample_dark_output_images = dark_outputs[sample_indices]\n",
    "\n",
    "            # Display the images\n",
    "            plot_images(sample_dark_input_images, sample_dark_output_images, sample_dark_target_images, epoch)\n",
    "\n",
    "# Compute and print the average PSNR for input and output on the dark dataset\n",
    "avg_dark_psnr_input = np.mean(dark_img_psnr)\n",
    "avg_dark_psnr_output = np.mean(dark_out_psnr)\n",
    "print(f'Average PSNR for Dark Input Images: {avg_dark_psnr_input}')\n",
    "print(f'Average PSNR for Dark Output Images: {avg_dark_psnr_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Would the PSNR improve if I added a transformation for brightness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data transformations including ColorJitter\n",
    "transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.2),  # Adjust brightness with a random factor up to 0.2\n",
    "    transforms.Resize((256, 256)),            # Resize images to the target size\n",
    "    transforms.ToTensor(),                   # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Create custom datasets for dark dataset\n",
    "dark_dataset_A = CustomDataset(dark_dataset_path_A, transform=transform)\n",
    "dark_dataset_B = CustomDataset(dark_dataset_path_B, transform=transform)\n",
    "\n",
    "# Create data loaders for dark dataset\n",
    "dark_loader_A = DataLoader(dark_dataset_A, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dark_loader_B = DataLoader(dark_dataset_B, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = U_Net(in_ch=3, out_ch=3).cuda()\n",
    "model.load_state_dict(torch.load(\"./trained_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Lists to store validation PSNR scores\n",
    "dark_img_psnr = []\n",
    "dark_out_psnr = []\n",
    "\n",
    "# Testing loop on the dark dataset\n",
    "with torch.no_grad():\n",
    "    for idx, (darkA_batch, darkB_batch) in tqdm(enumerate(zip(dark_loader_A, dark_loader_B)), total=len(dark_loader_A), desc='Testing on Dark Dataset'):\n",
    "        dark_input_images = darkA_batch.cuda()\n",
    "        dark_target_images = darkB_batch.cuda()\n",
    "\n",
    "        # Apply the model to input images\n",
    "        dark_outputs = model(dark_input_images)\n",
    "\n",
    "        # Compute PSNR scores\n",
    "        dark_psnr_input = PSNR(dark_input_images, dark_target_images)\n",
    "        dark_psnr_output = PSNR(dark_outputs, dark_target_images)\n",
    "\n",
    "        # Append PSNR scores to the lists\n",
    "        dark_img_psnr.append(dark_psnr_input.item())\n",
    "        dark_out_psnr.append(dark_psnr_output.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Take a few samples from the batch\n",
    "            sample_indices = np.random.choice(len(dark_input_images), size=num_samples, replace=False)\n",
    "            sample_dark_input_images = dark_input_images[sample_indices]\n",
    "            sample_dark_target_images = dark_target_images[sample_indices]\n",
    "            sample_dark_output_images = dark_outputs[sample_indices]\n",
    "\n",
    "            # Display the images\n",
    "            plot_images(sample_dark_input_images, sample_dark_output_images, sample_dark_target_images, epoch)\n",
    "\n",
    "# Compute and print the average PSNR for input and output on the dark dataset\n",
    "avg_dark_psnr_input = np.mean(dark_img_psnr)\n",
    "avg_dark_psnr_output = np.mean(dark_out_psnr)\n",
    "print(f'Average PSNR for transformed Dark Input Images: {avg_dark_psnr_input}')\n",
    "print(f'Average PSNR for transformed Dark Output Images: {avg_dark_psnr_output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
